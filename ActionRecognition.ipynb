{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTGtUIc1neV3",
        "outputId": "2229ae64-0acf-4e64-ee3d-72d280d40bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mdu-VOaUKma4"
      },
      "outputs": [],
      "source": [
        "#Required Imports\n",
        "import os\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('AGG')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "\n",
        "from keras.layers import (Input, Activation, Conv3D, Dense, Dropout, Flatten, MaxPooling3D, Input, average, BatchNormalization, LeakyReLU)\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jptgr_XSHXmi",
        "outputId": "9d59965b-fdb0-4ac0-88a2-0eb474f36d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available: 1\n"
          ]
        }
      ],
      "source": [
        "# Check GPU Availability\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "#Reduce Precision From float32 To float16\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "#Accelerated Linear Algebra\n",
        "tf.config.optimizer.set_jit(True)\n",
        "\n",
        "# Create An Optimizer With Loss Scaling To Prevent Precision Issues\n",
        "# from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# opt = LossScaleOptimizer(Adam(learning_rate=1e-4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RXAaQcJ6K33m"
      },
      "outputs": [],
      "source": [
        "#Class To Extract Frames From Video (Converting Video File To 3D Array For Processing)\n",
        "class Videoto3D:\n",
        "\n",
        "  def __init__(self, width, height, depth):\n",
        "    self.width = width\n",
        "    self.height = height\n",
        "    self.depth = depth\n",
        "\n",
        "  #Skip Frames In The Video For Efficiency\n",
        "  def video3d(self, filename, color=False, skip=True):\n",
        "    cap = cv2.VideoCapture(filename)\n",
        "    nframe = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    if skip:\n",
        "      frames = [x * nframe / self.depth for x in range(self.depth)]\n",
        "    else:\n",
        "      frames = [x for x in range(self.depth)]\n",
        "    framearray = []\n",
        "\n",
        "    for i in range(self.depth):\n",
        "      cap.set(cv2.CAP_PROP_POS_FRAMES, frames[i])\n",
        "      ret, frame = cap.read()\n",
        "      frame = cv2.resize(frame, (self.height, self.width))\n",
        "      if color:\n",
        "        framearray.append(frame)\n",
        "      else:\n",
        "        framearray.append(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(framearray) #Outputs A Numpy Array For Each Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TVw6ET62YUrr"
      },
      "outputs": [],
      "source": [
        "#Function To Load Videos And Labels\n",
        "def loaddata(video_dir, vid3d, nclass, labellist, result_dir, color=False, skip=True):\n",
        "\n",
        "  categories = sorted(os.listdir(video_dir)) #One Folder Per Category\n",
        "  X = []\n",
        "  labels = []\n",
        "  labellist = []\n",
        "\n",
        "  total_categories = len(categories)  # For Progress Bar\n",
        "  pbar = tqdm(total=total_categories, desc=\"Processing Directories\")\n",
        "\n",
        "  for category in categories:\n",
        "\n",
        "    if category in ['.DS_Store', 'output'] :\n",
        "      continue\n",
        "\n",
        "    category_path = os.path.join(video_dir, category)\n",
        "\n",
        "    if category not in labellist:\n",
        "      if len(labellist) >= nclass: #Only Process Given Amount Of Classes\n",
        "        break\n",
        "      labellist.append(category)\n",
        "\n",
        "    files = os.listdir(category_path)\n",
        "    for filename in files:\n",
        "\n",
        "      if filename == '.DS_Store':\n",
        "        continue\n",
        "\n",
        "      file_path = os.path.join(category_path, filename)\n",
        "      X.append(vid3d.video3d(file_path, color=color, skip=skip))\n",
        "      labels.append(category)\n",
        "\n",
        "    pbar.update(1)\n",
        "\n",
        "  pbar.close()\n",
        "\n",
        "  for num, label in enumerate(labellist): #Assign Numbers For Classes\n",
        "    for i in range(len(labels)):\n",
        "      if label == labels[i]:\n",
        "        labels[i] = num\n",
        "\n",
        "  if color:\n",
        "    return np.array(X).transpose((0, 2, 3, 4, 1)), labels #(num_samples, height, width, depth, channels)\n",
        "  else:\n",
        "    return np.array(X).transpose((0, 2, 3, 1)), labels #(num_samples, height, width, depth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "97zGUDunaP6m"
      },
      "outputs": [],
      "source": [
        "#Creating A 3D Convolutional Neural Network With Leaky Relu & Batch Normalization\n",
        "def create_3dcnn(input_shape, n_classes):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Input(shape=input_shape))\n",
        "  model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
        "  model.add(BatchNormalization())  # Standardize activations\n",
        "  model.add(LeakyReLU(negative_slope=0.01)) # Leaky ReLU instead of ReLU\n",
        "\n",
        "  model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(negative_slope=0.01))\n",
        "\n",
        "  model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(negative_slope=0.01))\n",
        "\n",
        "  model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(negative_slope=0.01))\n",
        "\n",
        "  model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv3D(128, kernel_size=(3,3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(negative_slope=0.01))\n",
        "\n",
        "  model.add(Conv3D(128, kernel_size=(3,3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(negative_slope=0.01))\n",
        "\n",
        "  model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(negative_slope=0.01))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4RKb0ReFEuNX"
      },
      "outputs": [],
      "source": [
        "#Variables\n",
        "in_dir = '/content/drive/MyDrive/UCF-101'\n",
        "\n",
        "out_dir = '/content/drive/MyDrive/UCF-101/output'\n",
        "if not os.path.isdir(out_dir): #Create Directory If It Doesn't Exist\n",
        "  os.makedirs(out_dir)\n",
        "\n",
        "model_weights = '/content/drive/MyDrive/UCF-101/output/model_weights'\n",
        "if not os.path.isdir(model_weights):\n",
        "  os.makedirs(model_weights)\n",
        "\n",
        "results = '/content/drive/MyDrive/UCF-101/output/results'\n",
        "if not os.path.isdir(results):\n",
        "  os.makedirs(results)\n",
        "\n",
        "n_models = 10\n",
        "n_classes = 101\n",
        "img_rows,img_cols,frames = 32,32,10\n",
        "\n",
        "color = False\n",
        "skip = True\n",
        "\n",
        "channel = 3 if color else 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IQotsGPoTU43"
      },
      "outputs": [],
      "source": [
        "#Saving Each Model's Training/Validation Accuracy & Loss\n",
        "def plot_history(history, name):\n",
        "  plt.plot(history.history['accuracy'], marker='.')\n",
        "  plt.plot(history.history['val_accuracy'], marker='.')\n",
        "  plt.title('model accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.grid()\n",
        "  plt.savefig(os.path.join(results, '{}_accuracy.png'.format(name)))\n",
        "  plt.close()\n",
        "\n",
        "  plt.plot(history.history['loss'], marker='.')\n",
        "  plt.plot(history.history['val_loss'], marker='.')\n",
        "  plt.title('model loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.grid()\n",
        "  plt.savefig(os.path.join(results, '{}_loss.png'.format(name)))\n",
        "  plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlqQFFZ4EINy",
        "outputId": "dbf606b5-ee1b-4185-b840-b46cec83b587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_shape:(13320, 32, 32, 10, 1) Y_shape:(13320, 101)\n"
          ]
        }
      ],
      "source": [
        "#Function To Load Training & Testing Data\n",
        "def Train_Test_Data():\n",
        "\n",
        "  vid3d = Videoto3D(img_rows, img_cols, frames)\n",
        "\n",
        "  preloaded_data_path = '/content/drive/MyDrive/UCF-101/output/dataset.npz'\n",
        "\n",
        "  if os.path.exists(preloaded_data_path): #Load Data If It Already Exists\n",
        "    loadeddata = np.load(preloaded_data_path)\n",
        "    X, Y = loadeddata[\"X\"], loadeddata[\"Y\"]\n",
        "  else:\n",
        "    x, y = loaddata(in_dir, vid3d, n_classes, out_dir, color, skip) #Load And Save Data If It Doesn't Exist\n",
        "    X = x.reshape((x.shape[0], img_rows, img_cols, frames, channel))\n",
        "    Y = to_categorical(y, n_classes)\n",
        "\n",
        "    X = X.astype('float16')\n",
        "    np.savez(preloaded_data_path, X=X, Y=Y)\n",
        "  print('X_shape:{} Y_shape:{}'.format(X.shape, Y.shape))\n",
        "\n",
        "  return train_test_split(X, Y, test_size=0.2), X.shape[1: ]\n",
        "\n",
        "(X_train, X_test, Y_train, Y_test), in_shape = Train_Test_Data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8it1dErja77O"
      },
      "outputs": [],
      "source": [
        "#Function To Train An Ensemble Of Models\n",
        "def train_model(epochs=100, batch_size=128):\n",
        "\n",
        "  #Train Test Generator\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(len(X_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  #Implementing Model CallBacks\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
        "\n",
        "  #Training Models Individually\n",
        "  models=[]\n",
        "  for i in range(n_models):\n",
        "    print(f\"Model {i}:\")\n",
        "    models.append(create_3dcnn(in_shape, n_classes))\n",
        "    models[-1].compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model_path = os.path.join(model_weights, f\"model_{i}.h5\")\n",
        "\n",
        "    #Load Weights If Model Already Trained\n",
        "    if os.path.exists(model_path):\n",
        "      models[-1] = load_model(model_path)\n",
        "      print(f\"Model {i} weights loaded from: {model_path}\")\n",
        "\n",
        "    #Train The Model If Weights Do Not Exist\n",
        "    else:\n",
        "      history = models[-1].fit(train_dataset, validation_data=test_dataset, epochs=epochs, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
        "      models[-1].save(model_path)\n",
        "      print(f\"Model {i} weights saved at: {model_path}\")\n",
        "      plot_history(history, i)\n",
        "\n",
        "  #Creating An Ensemble Model\n",
        "  model_inputs = [Input(shape=in_shape) for _ in range (n_models)]\n",
        "  model_outputs = [models[i](model_inputs[i]) for i in range (n_models)]\n",
        "  model_outputs = average(inputs=model_outputs)\n",
        "  model = Model(inputs=model_inputs, outputs=model_outputs)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.save(os.path.join(out_dir, 'ucf101_3dcnnmodel.h5'))\n",
        "\n",
        "  X_test_copies = [np.copy(X_test) for _ in range(n_models)]\n",
        "  loss, acc = model.evaluate(X_test_copies, Y_test, verbose=0)\n",
        "  with open(os.path.join(out_dir, 'result.txt'), 'w') as f:\n",
        "    f.write(f\"Test loss: {loss:.4f}, Test accuracy: {acc:.4f}\")\n",
        "\n",
        "  print('merged model:')\n",
        "  print('Test loss:', loss)\n",
        "  print('Test accuracy:', acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7m-EJoPPnToS",
        "outputId": "5e1cebaa-df0c-4942-d598-0139bcec8057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 0:\n",
            "Epoch 1/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 264ms/step - accuracy: 0.0309 - loss: 4.9982 - val_accuracy: 0.0762 - val_loss: 4.9609 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.1341 - loss: 3.7418 - val_accuracy: 0.0360 - val_loss: 5.6272 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.2456 - loss: 3.0189 - val_accuracy: 0.1580 - val_loss: 4.2203 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.3559 - loss: 2.5003 - val_accuracy: 0.3607 - val_loss: 2.5204 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.4451 - loss: 2.1295 - val_accuracy: 0.4133 - val_loss: 2.3021 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.5233 - loss: 1.7859 - val_accuracy: 0.4872 - val_loss: 1.9979 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.5984 - loss: 1.5040 - val_accuracy: 0.5822 - val_loss: 1.6428 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.6378 - loss: 1.3335 - val_accuracy: 0.5785 - val_loss: 1.6192 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.6905 - loss: 1.1303 - val_accuracy: 0.5908 - val_loss: 1.6254 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.7312 - loss: 0.9671 - val_accuracy: 0.6959 - val_loss: 1.2084 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7779 - loss: 0.8224 - val_accuracy: 0.7140 - val_loss: 1.1003 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.8005 - loss: 0.7193 - val_accuracy: 0.6907 - val_loss: 1.1991 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.8268 - loss: 0.6347 - val_accuracy: 0.7721 - val_loss: 0.8938 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8433 - loss: 0.5566 - val_accuracy: 0.7087 - val_loss: 1.1043 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.8599 - loss: 0.5009 - val_accuracy: 0.7425 - val_loss: 0.9918 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8842 - loss: 0.4268 - val_accuracy: 0.7616 - val_loss: 0.9254 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8896 - loss: 0.3897 - val_accuracy: 0.7688 - val_loss: 0.9142 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9033 - loss: 0.3438 - val_accuracy: 0.8007 - val_loss: 0.7609 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9202 - loss: 0.2972 - val_accuracy: 0.7575 - val_loss: 0.9134 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9195 - loss: 0.2840 - val_accuracy: 0.8176 - val_loss: 0.7249 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9366 - loss: 0.2297 - val_accuracy: 0.8037 - val_loss: 0.7745 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9410 - loss: 0.2129 - val_accuracy: 0.8078 - val_loss: 0.7815 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9423 - loss: 0.2145 - val_accuracy: 0.7384 - val_loss: 1.1420 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9502 - loss: 0.1833 - val_accuracy: 0.8123 - val_loss: 0.7501 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m83/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9523 - loss: 0.1728\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9523 - loss: 0.1728 - val_accuracy: 0.8101 - val_loss: 0.7794 - learning_rate: 0.0010\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 0 weights saved at: /content/drive/MyDrive/UCF-101/output/model_weights/model_0.h5\n",
            "Model 1:\n",
            "Epoch 1/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 176ms/step - accuracy: 0.0218 - loss: 5.0872 - val_accuracy: 0.0518 - val_loss: 6.3325 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.1304 - loss: 3.7882 - val_accuracy: 0.1201 - val_loss: 3.9130 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.2419 - loss: 3.0220 - val_accuracy: 0.2335 - val_loss: 3.1110 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.3450 - loss: 2.5713 - val_accuracy: 0.3161 - val_loss: 2.7233 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.4444 - loss: 2.1104 - val_accuracy: 0.4471 - val_loss: 2.1480 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.5298 - loss: 1.7915 - val_accuracy: 0.5150 - val_loss: 1.8535 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.5940 - loss: 1.5141 - val_accuracy: 0.5841 - val_loss: 1.5855 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.6435 - loss: 1.3241 - val_accuracy: 0.5897 - val_loss: 1.6361 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.6999 - loss: 1.1216 - val_accuracy: 0.6509 - val_loss: 1.3505 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.7398 - loss: 0.9545 - val_accuracy: 0.6321 - val_loss: 1.4025 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7778 - loss: 0.8273 - val_accuracy: 0.7057 - val_loss: 1.1441 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8058 - loss: 0.7051 - val_accuracy: 0.7624 - val_loss: 0.9031 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8366 - loss: 0.6104 - val_accuracy: 0.7061 - val_loss: 1.1332 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8465 - loss: 0.5495 - val_accuracy: 0.7691 - val_loss: 0.8861 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8636 - loss: 0.4904 - val_accuracy: 0.7703 - val_loss: 0.9099 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.8810 - loss: 0.4221 - val_accuracy: 0.7770 - val_loss: 0.8530 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.8903 - loss: 0.3811 - val_accuracy: 0.7917 - val_loss: 0.7757 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9112 - loss: 0.3187 - val_accuracy: 0.8078 - val_loss: 0.7519 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9244 - loss: 0.2830 - val_accuracy: 0.7395 - val_loss: 1.0507 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9146 - loss: 0.2904 - val_accuracy: 0.7515 - val_loss: 0.9476 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9331 - loss: 0.2498 - val_accuracy: 0.7954 - val_loss: 0.8029 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9378 - loss: 0.2132 - val_accuracy: 0.7639 - val_loss: 0.9412 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9459 - loss: 0.1947 - val_accuracy: 0.8198 - val_loss: 0.7098 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.9497 - loss: 0.1873 - val_accuracy: 0.8168 - val_loss: 0.7324 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9554 - loss: 0.1675 - val_accuracy: 0.8206 - val_loss: 0.7190 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9525 - loss: 0.1604 - val_accuracy: 0.8281 - val_loss: 0.6831 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9594 - loss: 0.1416 - val_accuracy: 0.8097 - val_loss: 0.7711 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9659 - loss: 0.1325 - val_accuracy: 0.8041 - val_loss: 0.7943 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9647 - loss: 0.1268 - val_accuracy: 0.8341 - val_loss: 0.6827 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.9658 - loss: 0.1170 - val_accuracy: 0.7898 - val_loss: 0.8425 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9663 - loss: 0.1163 - val_accuracy: 0.8258 - val_loss: 0.7194 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9711 - loss: 0.1070 - val_accuracy: 0.8360 - val_loss: 0.6703 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9703 - loss: 0.1052 - val_accuracy: 0.8149 - val_loss: 0.7745 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9695 - loss: 0.1105 - val_accuracy: 0.8097 - val_loss: 0.7704 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9721 - loss: 0.0987 - val_accuracy: 0.8363 - val_loss: 0.6792 - learning_rate: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9740 - loss: 0.0947 - val_accuracy: 0.8390 - val_loss: 0.7074 - learning_rate: 0.0010\n",
            "Epoch 37/100\n",
            "\u001b[1m83/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9749 - loss: 0.0882\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9749 - loss: 0.0881 - val_accuracy: 0.8018 - val_loss: 0.8441 - learning_rate: 0.0010\n",
            "Epoch 37: early stopping\n",
            "Restoring model weights from the end of the best epoch: 32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 weights saved at: /content/drive/MyDrive/UCF-101/output/model_weights/model_1.h5\n",
            "Model 2:\n",
            "Epoch 1/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 163ms/step - accuracy: 0.0297 - loss: 5.0034 - val_accuracy: 0.0458 - val_loss: 5.5848 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 63ms/step - accuracy: 0.1375 - loss: 3.7129 - val_accuracy: 0.2091 - val_loss: 3.1782 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.2546 - loss: 2.9853 - val_accuracy: 0.2793 - val_loss: 2.8932 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.3709 - loss: 2.4476 - val_accuracy: 0.3956 - val_loss: 2.2851 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.4476 - loss: 2.1124 - val_accuracy: 0.4167 - val_loss: 2.2658 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.5404 - loss: 1.7319 - val_accuracy: 0.5169 - val_loss: 1.9074 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.6054 - loss: 1.5027 - val_accuracy: 0.6122 - val_loss: 1.5369 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.6603 - loss: 1.2441 - val_accuracy: 0.6640 - val_loss: 1.3198 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.7012 - loss: 1.0986 - val_accuracy: 0.5886 - val_loss: 1.6077 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7433 - loss: 0.9506 - val_accuracy: 0.6509 - val_loss: 1.3035 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7933 - loss: 0.7816 - val_accuracy: 0.6963 - val_loss: 1.1953 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.8111 - loss: 0.6779 - val_accuracy: 0.7339 - val_loss: 1.0219 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.8263 - loss: 0.6303 - val_accuracy: 0.7158 - val_loss: 1.1401 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8517 - loss: 0.5431 - val_accuracy: 0.7286 - val_loss: 1.0956 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8672 - loss: 0.4771 - val_accuracy: 0.7860 - val_loss: 0.8240 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.8836 - loss: 0.4042 - val_accuracy: 0.7797 - val_loss: 0.8960 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8978 - loss: 0.3633 - val_accuracy: 0.7935 - val_loss: 0.7958 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9105 - loss: 0.3286 - val_accuracy: 0.7812 - val_loss: 0.8447 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9125 - loss: 0.3052 - val_accuracy: 0.7729 - val_loss: 0.8759 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9288 - loss: 0.2637 - val_accuracy: 0.8033 - val_loss: 0.7741 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9365 - loss: 0.2329 - val_accuracy: 0.7868 - val_loss: 0.8627 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9411 - loss: 0.2148 - val_accuracy: 0.8018 - val_loss: 0.7511 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9414 - loss: 0.2027 - val_accuracy: 0.8033 - val_loss: 0.7610 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9473 - loss: 0.1837 - val_accuracy: 0.8228 - val_loss: 0.7067 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9537 - loss: 0.1736 - val_accuracy: 0.8341 - val_loss: 0.6675 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9558 - loss: 0.1571 - val_accuracy: 0.8134 - val_loss: 0.7584 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9579 - loss: 0.1514 - val_accuracy: 0.7932 - val_loss: 0.8825 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9628 - loss: 0.1368 - val_accuracy: 0.8296 - val_loss: 0.7156 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9629 - loss: 0.1362 - val_accuracy: 0.8401 - val_loss: 0.6622 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9683 - loss: 0.1138 - val_accuracy: 0.8367 - val_loss: 0.6583 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9573 - loss: 0.1470 - val_accuracy: 0.8326 - val_loss: 0.7055 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9671 - loss: 0.1146 - val_accuracy: 0.8337 - val_loss: 0.6951 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9743 - loss: 0.0964 - val_accuracy: 0.8074 - val_loss: 0.8177 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9722 - loss: 0.0982 - val_accuracy: 0.8224 - val_loss: 0.7507 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m83/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9668 - loss: 0.1141\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9668 - loss: 0.1142 - val_accuracy: 0.8161 - val_loss: 0.7974 - learning_rate: 0.0010\n",
            "Epoch 35: early stopping\n",
            "Restoring model weights from the end of the best epoch: 30.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 2 weights saved at: /content/drive/MyDrive/UCF-101/output/model_weights/model_2.h5\n",
            "Model 3:\n",
            "Epoch 1/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 178ms/step - accuracy: 0.0271 - loss: 5.0366 - val_accuracy: 0.0360 - val_loss: 9.6204 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.1338 - loss: 3.7881 - val_accuracy: 0.1479 - val_loss: 3.6520 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.2604 - loss: 2.9829 - val_accuracy: 0.2286 - val_loss: 3.2422 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.3727 - loss: 2.4489 - val_accuracy: 0.2639 - val_loss: 2.9730 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.4509 - loss: 2.0857 - val_accuracy: 0.4486 - val_loss: 2.1183 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.5408 - loss: 1.7418 - val_accuracy: 0.5586 - val_loss: 1.7253 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.5960 - loss: 1.4997 - val_accuracy: 0.6400 - val_loss: 1.4615 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.6520 - loss: 1.2778 - val_accuracy: 0.5942 - val_loss: 1.5658 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7005 - loss: 1.1199 - val_accuracy: 0.6265 - val_loss: 1.4905 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.7563 - loss: 0.9116 - val_accuracy: 0.6956 - val_loss: 1.2162 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.7942 - loss: 0.7745 - val_accuracy: 0.7196 - val_loss: 1.0952 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.8151 - loss: 0.6886 - val_accuracy: 0.7008 - val_loss: 1.1598 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8401 - loss: 0.5813 - val_accuracy: 0.6903 - val_loss: 1.1608 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8444 - loss: 0.5450 - val_accuracy: 0.7395 - val_loss: 1.0034 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.8763 - loss: 0.4533 - val_accuracy: 0.7718 - val_loss: 0.8767 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8833 - loss: 0.4165 - val_accuracy: 0.7414 - val_loss: 0.9716 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.8945 - loss: 0.3692 - val_accuracy: 0.7534 - val_loss: 0.9437 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9135 - loss: 0.3215 - val_accuracy: 0.7887 - val_loss: 0.8199 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9184 - loss: 0.2891 - val_accuracy: 0.8243 - val_loss: 0.6934 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9301 - loss: 0.2445 - val_accuracy: 0.7984 - val_loss: 0.7907 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9340 - loss: 0.2311 - val_accuracy: 0.8089 - val_loss: 0.7344 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9415 - loss: 0.2167 - val_accuracy: 0.8285 - val_loss: 0.6719 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9554 - loss: 0.1692 - val_accuracy: 0.8270 - val_loss: 0.6623 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9491 - loss: 0.1835 - val_accuracy: 0.8382 - val_loss: 0.6613 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9563 - loss: 0.1641 - val_accuracy: 0.7883 - val_loss: 0.8571 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9556 - loss: 0.1619 - val_accuracy: 0.8138 - val_loss: 0.7488 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9527 - loss: 0.1587 - val_accuracy: 0.8401 - val_loss: 0.6704 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9615 - loss: 0.1411 - val_accuracy: 0.8221 - val_loss: 0.7663 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m83/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9548 - loss: 0.1448\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9548 - loss: 0.1447 - val_accuracy: 0.8236 - val_loss: 0.7214 - learning_rate: 0.0010\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 24.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 3 weights saved at: /content/drive/MyDrive/UCF-101/output/model_weights/model_3.h5\n",
            "Model 4:\n",
            "Epoch 1/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 175ms/step - accuracy: 0.0290 - loss: 4.9866 - val_accuracy: 0.0601 - val_loss: 5.8032 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.1371 - loss: 3.7294 - val_accuracy: 0.2218 - val_loss: 3.1558 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.2500 - loss: 3.0225 - val_accuracy: 0.1569 - val_loss: 3.7542 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.3523 - loss: 2.4941 - val_accuracy: 0.3179 - val_loss: 2.8743 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.4453 - loss: 2.1062 - val_accuracy: 0.3934 - val_loss: 2.3815 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.5366 - loss: 1.7545 - val_accuracy: 0.5522 - val_loss: 1.7811 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.6058 - loss: 1.5028 - val_accuracy: 0.6314 - val_loss: 1.4266 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.6625 - loss: 1.2734 - val_accuracy: 0.6186 - val_loss: 1.4806 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.6955 - loss: 1.1255 - val_accuracy: 0.6730 - val_loss: 1.2774 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.7432 - loss: 0.9540 - val_accuracy: 0.6430 - val_loss: 1.4287 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7778 - loss: 0.8141 - val_accuracy: 0.7248 - val_loss: 1.0713 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.7982 - loss: 0.7265 - val_accuracy: 0.6896 - val_loss: 1.1924 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8384 - loss: 0.5913 - val_accuracy: 0.7481 - val_loss: 0.9952 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8483 - loss: 0.5529 - val_accuracy: 0.7346 - val_loss: 1.0349 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8672 - loss: 0.4886 - val_accuracy: 0.7564 - val_loss: 0.9680 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8874 - loss: 0.4155 - val_accuracy: 0.7748 - val_loss: 0.8535 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8954 - loss: 0.3804 - val_accuracy: 0.7827 - val_loss: 0.8440 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9024 - loss: 0.3365 - val_accuracy: 0.7515 - val_loss: 1.0015 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9215 - loss: 0.2924 - val_accuracy: 0.7774 - val_loss: 0.8722 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9267 - loss: 0.2657 - val_accuracy: 0.7995 - val_loss: 0.8074 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9387 - loss: 0.2244 - val_accuracy: 0.8251 - val_loss: 0.6786 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9397 - loss: 0.2164 - val_accuracy: 0.7797 - val_loss: 0.8657 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.9461 - loss: 0.2034 - val_accuracy: 0.8029 - val_loss: 0.8059 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9518 - loss: 0.1833 - val_accuracy: 0.8333 - val_loss: 0.6675 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9503 - loss: 0.1748 - val_accuracy: 0.8059 - val_loss: 0.7799 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9578 - loss: 0.1568 - val_accuracy: 0.8258 - val_loss: 0.7037 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9664 - loss: 0.1332 - val_accuracy: 0.8142 - val_loss: 0.7509 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9618 - loss: 0.1412 - val_accuracy: 0.7624 - val_loss: 1.0144 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m83/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9680 - loss: 0.1194\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9679 - loss: 0.1195 - val_accuracy: 0.7962 - val_loss: 0.8019 - learning_rate: 0.0010\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 24.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 4 weights saved at: /content/drive/MyDrive/UCF-101/output/model_weights/model_4.h5\n",
            "Model 5:\n",
            "Epoch 1/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 183ms/step - accuracy: 0.0280 - loss: 5.0016 - val_accuracy: 0.0541 - val_loss: 5.2636 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.1353 - loss: 3.7398 - val_accuracy: 0.1486 - val_loss: 3.9505 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.2566 - loss: 2.9933 - val_accuracy: 0.2072 - val_loss: 3.4935 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.3678 - loss: 2.4772 - val_accuracy: 0.2598 - val_loss: 3.0923 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.4420 - loss: 2.0885 - val_accuracy: 0.4486 - val_loss: 2.1397 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.5334 - loss: 1.7691 - val_accuracy: 0.4215 - val_loss: 2.2803 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.5849 - loss: 1.5557 - val_accuracy: 0.6152 - val_loss: 1.4581 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.6556 - loss: 1.2859 - val_accuracy: 0.5544 - val_loss: 1.6883 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.6948 - loss: 1.1205 - val_accuracy: 0.6408 - val_loss: 1.3830 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.7331 - loss: 0.9621 - val_accuracy: 0.6881 - val_loss: 1.2423 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7748 - loss: 0.8385 - val_accuracy: 0.7020 - val_loss: 1.1096 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.8011 - loss: 0.7164 - val_accuracy: 0.7245 - val_loss: 1.0750 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.8279 - loss: 0.6259 - val_accuracy: 0.7380 - val_loss: 0.9920 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.8479 - loss: 0.5515 - val_accuracy: 0.7429 - val_loss: 0.9905 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.8621 - loss: 0.4938 - val_accuracy: 0.7609 - val_loss: 0.9239 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8766 - loss: 0.4332 - val_accuracy: 0.7121 - val_loss: 1.1445 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8894 - loss: 0.3892 - val_accuracy: 0.7718 - val_loss: 0.8603 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9093 - loss: 0.3316 - val_accuracy: 0.8011 - val_loss: 0.7726 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9200 - loss: 0.2928 - val_accuracy: 0.8082 - val_loss: 0.7679 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9276 - loss: 0.2616 - val_accuracy: 0.8104 - val_loss: 0.7335 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9322 - loss: 0.2432 - val_accuracy: 0.7939 - val_loss: 0.7994 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9374 - loss: 0.2232 - val_accuracy: 0.8255 - val_loss: 0.6820 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9418 - loss: 0.2106 - val_accuracy: 0.7819 - val_loss: 0.8501 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9478 - loss: 0.1920 - val_accuracy: 0.8311 - val_loss: 0.6740 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9451 - loss: 0.1910 - val_accuracy: 0.8236 - val_loss: 0.7076 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9569 - loss: 0.1610 - val_accuracy: 0.8337 - val_loss: 0.6685 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9588 - loss: 0.1464 - val_accuracy: 0.8048 - val_loss: 0.8029 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9646 - loss: 0.1336 - val_accuracy: 0.8311 - val_loss: 0.6803 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9635 - loss: 0.1399 - val_accuracy: 0.8093 - val_loss: 0.7731 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9600 - loss: 0.1411 - val_accuracy: 0.8277 - val_loss: 0.6921 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m83/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9653 - loss: 0.1234\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9652 - loss: 0.1235 - val_accuracy: 0.8149 - val_loss: 0.7514 - learning_rate: 0.0010\n",
            "Epoch 31: early stopping\n",
            "Restoring model weights from the end of the best epoch: 26.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 5 weights saved at: /content/drive/MyDrive/UCF-101/output/model_weights/model_5.h5\n",
            "Model 6:\n",
            "Epoch 1/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 177ms/step - accuracy: 0.0261 - loss: 5.0539 - val_accuracy: 0.0390 - val_loss: 7.2085 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.1384 - loss: 3.7430 - val_accuracy: 0.1107 - val_loss: 5.1385 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.2527 - loss: 2.9929 - val_accuracy: 0.1486 - val_loss: 4.1768 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.3537 - loss: 2.4912 - val_accuracy: 0.3258 - val_loss: 2.7750 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.4561 - loss: 2.0731 - val_accuracy: 0.3945 - val_loss: 2.3606 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.5191 - loss: 1.7921 - val_accuracy: 0.4809 - val_loss: 1.9808 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5928 - loss: 1.5067 - val_accuracy: 0.5454 - val_loss: 1.7614 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.6517 - loss: 1.2915 - val_accuracy: 0.6014 - val_loss: 1.5825 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7024 - loss: 1.1165 - val_accuracy: 0.5890 - val_loss: 1.6037 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.7511 - loss: 0.9383 - val_accuracy: 0.6629 - val_loss: 1.2910 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7689 - loss: 0.8424 - val_accuracy: 0.7072 - val_loss: 1.1542 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.8036 - loss: 0.7130 - val_accuracy: 0.6862 - val_loss: 1.2089 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8286 - loss: 0.6251 - val_accuracy: 0.7406 - val_loss: 0.9958 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8513 - loss: 0.5474 - val_accuracy: 0.7132 - val_loss: 1.1294 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8579 - loss: 0.4987 - val_accuracy: 0.7425 - val_loss: 1.0125 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.8846 - loss: 0.4161 - val_accuracy: 0.7849 - val_loss: 0.8414 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.8957 - loss: 0.3818 - val_accuracy: 0.7192 - val_loss: 1.0665 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9132 - loss: 0.3223 - val_accuracy: 0.7222 - val_loss: 1.0518 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.9141 - loss: 0.3008 - val_accuracy: 0.7673 - val_loss: 0.8932 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9241 - loss: 0.2652 - val_accuracy: 0.7815 - val_loss: 0.8219 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9339 - loss: 0.2444 - val_accuracy: 0.7845 - val_loss: 0.8278 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9304 - loss: 0.2397 - val_accuracy: 0.7860 - val_loss: 0.8241 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.9433 - loss: 0.2069 - val_accuracy: 0.8134 - val_loss: 0.7507 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9504 - loss: 0.1798 - val_accuracy: 0.7504 - val_loss: 0.9781 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9494 - loss: 0.1724 - val_accuracy: 0.7770 - val_loss: 0.9191 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9535 - loss: 0.1756 - val_accuracy: 0.7721 - val_loss: 0.9203 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9546 - loss: 0.1639 - val_accuracy: 0.8224 - val_loss: 0.7288 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9623 - loss: 0.1361 - val_accuracy: 0.7800 - val_loss: 0.9091 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9615 - loss: 0.1377 - val_accuracy: 0.7935 - val_loss: 0.8390 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9638 - loss: 0.1290 - val_accuracy: 0.8386 - val_loss: 0.6653 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9659 - loss: 0.1214 - val_accuracy: 0.8243 - val_loss: 0.7294 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9631 - loss: 0.1189 - val_accuracy: 0.8352 - val_loss: 0.6818 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9707 - loss: 0.1025 - val_accuracy: 0.8311 - val_loss: 0.7026 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9746 - loss: 0.0933 - val_accuracy: 0.7898 - val_loss: 0.9089 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m83/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9666 - loss: 0.1101\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9666 - loss: 0.1101 - val_accuracy: 0.8345 - val_loss: 0.7214 - learning_rate: 0.0010\n",
            "Epoch 35: early stopping\n",
            "Restoring model weights from the end of the best epoch: 30.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 6 weights saved at: /content/drive/MyDrive/UCF-101/output/model_weights/model_6.h5\n",
            "Model 7:\n",
            "Epoch 1/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 168ms/step - accuracy: 0.0249 - loss: 5.0297 - val_accuracy: 0.0345 - val_loss: 7.8368 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.1301 - loss: 3.7494 - val_accuracy: 0.1791 - val_loss: 3.4443 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.2514 - loss: 2.9930 - val_accuracy: 0.1682 - val_loss: 3.7474 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.3543 - loss: 2.4882 - val_accuracy: 0.3041 - val_loss: 2.6995 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.4462 - loss: 2.1074 - val_accuracy: 0.4606 - val_loss: 2.1012 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.5355 - loss: 1.7735 - val_accuracy: 0.4771 - val_loss: 1.9831 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.6039 - loss: 1.4964 - val_accuracy: 0.5856 - val_loss: 1.6364 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.6598 - loss: 1.2722 - val_accuracy: 0.6258 - val_loss: 1.4967 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.7035 - loss: 1.0829 - val_accuracy: 0.6288 - val_loss: 1.3888 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.7454 - loss: 0.9373 - val_accuracy: 0.6929 - val_loss: 1.2040 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7834 - loss: 0.7995 - val_accuracy: 0.7008 - val_loss: 1.1055 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8074 - loss: 0.7053 - val_accuracy: 0.7320 - val_loss: 1.0255 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8410 - loss: 0.5880 - val_accuracy: 0.7680 - val_loss: 0.8905 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8462 - loss: 0.5482 - val_accuracy: 0.6652 - val_loss: 1.3123 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.8671 - loss: 0.4863 - val_accuracy: 0.7733 - val_loss: 0.8646 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.8742 - loss: 0.4444 - val_accuracy: 0.7688 - val_loss: 0.8704 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8989 - loss: 0.3623 - val_accuracy: 0.7560 - val_loss: 0.9153 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9051 - loss: 0.3415 - val_accuracy: 0.7117 - val_loss: 1.1230 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9155 - loss: 0.3005 - val_accuracy: 0.7965 - val_loss: 0.7889 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9234 - loss: 0.2782 - val_accuracy: 0.8108 - val_loss: 0.7653 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9334 - loss: 0.2494 - val_accuracy: 0.7797 - val_loss: 0.8407 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9377 - loss: 0.2295 - val_accuracy: 0.7980 - val_loss: 0.7630 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9486 - loss: 0.1968 - val_accuracy: 0.8255 - val_loss: 0.6813 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.9507 - loss: 0.1781 - val_accuracy: 0.8063 - val_loss: 0.7740 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9462 - loss: 0.1887 - val_accuracy: 0.8037 - val_loss: 0.7856 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9607 - loss: 0.1474 - val_accuracy: 0.7845 - val_loss: 0.8705 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9616 - loss: 0.1419 - val_accuracy: 0.8228 - val_loss: 0.7475 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m83/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9579 - loss: 0.1421\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9580 - loss: 0.1420 - val_accuracy: 0.8228 - val_loss: 0.7452 - learning_rate: 0.0010\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 7 weights saved at: /content/drive/MyDrive/UCF-101/output/model_weights/model_7.h5\n",
            "Model 8:\n",
            "Epoch 1/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 157ms/step - accuracy: 0.0235 - loss: 5.0904 - val_accuracy: 0.0315 - val_loss: 6.0407 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.1276 - loss: 3.7651 - val_accuracy: 0.2080 - val_loss: 3.2067 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.2489 - loss: 3.0285 - val_accuracy: 0.2365 - val_loss: 3.1125 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.3606 - loss: 2.4436 - val_accuracy: 0.3266 - val_loss: 2.7192 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.4556 - loss: 2.0934 - val_accuracy: 0.4336 - val_loss: 2.2930 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.5416 - loss: 1.7349 - val_accuracy: 0.4985 - val_loss: 1.9505 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.6084 - loss: 1.4771 - val_accuracy: 0.5818 - val_loss: 1.5907 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.6671 - loss: 1.2689 - val_accuracy: 0.5998 - val_loss: 1.5552 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.7250 - loss: 1.0470 - val_accuracy: 0.6749 - val_loss: 1.2898 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7530 - loss: 0.9254 - val_accuracy: 0.6273 - val_loss: 1.4514 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7838 - loss: 0.7844 - val_accuracy: 0.7402 - val_loss: 1.0101 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.8091 - loss: 0.6922 - val_accuracy: 0.7331 - val_loss: 1.0863 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.8326 - loss: 0.6078 - val_accuracy: 0.7380 - val_loss: 1.0072 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8500 - loss: 0.5318 - val_accuracy: 0.7523 - val_loss: 0.9345 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8596 - loss: 0.4841 - val_accuracy: 0.7830 - val_loss: 0.8254 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8865 - loss: 0.3992 - val_accuracy: 0.7827 - val_loss: 0.8104 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8998 - loss: 0.3631 - val_accuracy: 0.7676 - val_loss: 0.8982 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9120 - loss: 0.3239 - val_accuracy: 0.7545 - val_loss: 0.9176 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9225 - loss: 0.2771 - val_accuracy: 0.8056 - val_loss: 0.7568 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9381 - loss: 0.2357 - val_accuracy: 0.8082 - val_loss: 0.7680 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9419 - loss: 0.2231 - val_accuracy: 0.7965 - val_loss: 0.8005 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9424 - loss: 0.2083 - val_accuracy: 0.8157 - val_loss: 0.7774 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9422 - loss: 0.2098 - val_accuracy: 0.8007 - val_loss: 0.8045 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m83/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9446 - loss: 0.1895\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9446 - loss: 0.1894 - val_accuracy: 0.8059 - val_loss: 0.7926 - learning_rate: 0.0010\n",
            "Epoch 24: early stopping\n",
            "Restoring model weights from the end of the best epoch: 19.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 8 weights saved at: /content/drive/MyDrive/UCF-101/output/model_weights/model_8.h5\n",
            "Model 9:\n",
            "Epoch 1/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 159ms/step - accuracy: 0.0267 - loss: 5.0492 - val_accuracy: 0.0541 - val_loss: 5.2423 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.1392 - loss: 3.6645 - val_accuracy: 0.1877 - val_loss: 3.6309 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.2524 - loss: 2.9896 - val_accuracy: 0.2447 - val_loss: 3.0214 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.3544 - loss: 2.4930 - val_accuracy: 0.1963 - val_loss: 3.3509 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.4401 - loss: 2.1293 - val_accuracy: 0.3986 - val_loss: 2.3398 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.5234 - loss: 1.8083 - val_accuracy: 0.4535 - val_loss: 2.2163 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.5845 - loss: 1.5390 - val_accuracy: 0.5428 - val_loss: 1.7619 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.6523 - loss: 1.2918 - val_accuracy: 0.5890 - val_loss: 1.6115 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.6970 - loss: 1.0958 - val_accuracy: 0.6104 - val_loss: 1.4847 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7333 - loss: 0.9795 - val_accuracy: 0.6929 - val_loss: 1.1840 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7794 - loss: 0.8101 - val_accuracy: 0.6580 - val_loss: 1.2853 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.8119 - loss: 0.6961 - val_accuracy: 0.6847 - val_loss: 1.2834 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8327 - loss: 0.6138 - val_accuracy: 0.6565 - val_loss: 1.3865 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.8523 - loss: 0.5321 - val_accuracy: 0.7819 - val_loss: 0.8359 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8717 - loss: 0.4645 - val_accuracy: 0.7286 - val_loss: 1.0531 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8837 - loss: 0.4187 - val_accuracy: 0.6873 - val_loss: 1.1980 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9005 - loss: 0.3595 - val_accuracy: 0.7384 - val_loss: 1.0219 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9038 - loss: 0.3351 - val_accuracy: 0.7628 - val_loss: 0.9060 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9217 - loss: 0.2853 - val_accuracy: 0.8172 - val_loss: 0.7292 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9273 - loss: 0.2574 - val_accuracy: 0.7560 - val_loss: 0.9561 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9345 - loss: 0.2381 - val_accuracy: 0.7609 - val_loss: 0.9798 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9318 - loss: 0.2338 - val_accuracy: 0.7913 - val_loss: 0.8021 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9466 - loss: 0.1942 - val_accuracy: 0.8288 - val_loss: 0.6657 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9498 - loss: 0.1808 - val_accuracy: 0.8022 - val_loss: 0.8242 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9496 - loss: 0.1776 - val_accuracy: 0.8179 - val_loss: 0.7315 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9519 - loss: 0.1678 - val_accuracy: 0.8153 - val_loss: 0.7579 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9608 - loss: 0.1450 - val_accuracy: 0.8251 - val_loss: 0.7153 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m83/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9671 - loss: 0.1217\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9670 - loss: 0.1218 - val_accuracy: 0.8393 - val_loss: 0.6810 - learning_rate: 0.0010\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 9 weights saved at: /content/drive/MyDrive/UCF-101/output/model_weights/model_9.h5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1066\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1066\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_27            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_28            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_29            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_30            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_31            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_32            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_33            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_34            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_35            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_16             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_17             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_18             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_19             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_20             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_21             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_22             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_23             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_24             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_25             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ average (\u001b[38;5;33mAverage\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ sequential_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_27            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_28            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_29            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_30            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_31            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_32            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_33            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_34            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_35            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_16             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_17             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_18             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_19             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_20             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_21             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_22             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_23             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_24             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_25             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ average (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Average</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,631,410\u001b[0m (74.89 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,631,410</span> (74.89 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,612,210\u001b[0m (74.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,612,210</span> (74.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m19,200\u001b[0m (75.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,200</span> (75.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merged model:\n",
            "Test loss: 0.5044229626655579\n",
            "Test accuracy: 0.8802552819252014\n"
          ]
        }
      ],
      "source": [
        "train_model() #Default Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Model For Prediction\n",
        "model_path = os.path.join(out_dir, 'ucf101_3dcnnmodel.h5')\n",
        "model = load_model(model_path, custom_objects={'average': average})\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NtWQ3Q0gheWM",
        "outputId": "e911791d-f004-4fa5-d5dc-d9a21ce99049"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1066\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1066\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_27            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_28            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_29            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_30            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_31            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_32            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_33            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_34            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_35            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_16             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_17             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_18             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_19             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_20             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_21             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_22             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_23             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_24             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_25             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │      \u001b[38;5;34m1,963,141\u001b[0m │ input_layer_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ average (\u001b[38;5;33mAverage\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ sequential_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ sequential_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_27            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_28            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_29            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_30            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_31            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_32            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_33            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_34            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_35            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_16             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_17             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_18             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_19             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_20             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_21             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_22             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_23             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_24             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_25             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,963,141</span> │ input_layer_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ average (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Average</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ sequential_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,631,416\u001b[0m (74.89 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,631,416</span> (74.89 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,612,210\u001b[0m (74.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,612,210</span> (74.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m19,200\u001b[0m (75.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,200</span> (75.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6\u001b[0m (36.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (36.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function To Load Category Labels\n",
        "def load_labels():\n",
        "  labellist = []\n",
        "  categories = sorted(os.listdir(in_dir)) #One Folder Per Category\n",
        "\n",
        "  for category in categories:\n",
        "    if category in ['.DS_Store', 'output']: #Ensure Only Categories Are Read\n",
        "      continue\n",
        "\n",
        "    category_path = os.path.join(in_dir, category)\n",
        "\n",
        "    if category not in labellist:\n",
        "      if len(labellist) >= n_classes: #Only Process Given Amount Of Classes\n",
        "        break\n",
        "      labellist.append(category)\n",
        "  return labellist\n",
        "\n",
        "#Function For Testing Model Predictions On Samples\n",
        "def test_model_on_example(model, X_test, Y_test, labellist, example_index=0):\n",
        "  sample = X_test[example_index]\n",
        "  sample = np.expand_dims(sample, axis=0)\n",
        "  sample = [np.copy(sample) for _ in range(n_models)]\n",
        "  true_label = np.argmax(Y_test[example_index])\n",
        "\n",
        "  prediction = model.predict(sample)\n",
        "  predicted_label = np.argmax(prediction)\n",
        "\n",
        "  print(f\"True Label: {labellist[true_label]}\")\n",
        "  print(f\"Predicted Label: {labellist[predicted_label]}\")\n",
        "\n",
        "  return true_label, predicted_label\n",
        "\n",
        "\n",
        "labellist = load_labels()\n",
        "\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "for i in range(100): #First 100 Sample Predictions\n",
        "  true_label, predicted_label = test_model_on_example(model, X_test, Y_test, labellist, example_index=i)\n",
        "  total_predictions += 1\n",
        "  if true_label == predicted_label:\n",
        "    correct_predictions += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-ZrLgs3ic3-",
        "outputId": "c576d4e6-7679-4291-ad19-4ae171e9616f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "True Label: YoYo\n",
            "Predicted Label: PizzaTossing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: Basketball\n",
            "Predicted Label: Basketball\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: BaseballPitch\n",
            "Predicted Label: BaseballPitch\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "True Label: Diving\n",
            "Predicted Label: Diving\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: Drumming\n",
            "Predicted Label: Drumming\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: PlayingCello\n",
            "Predicted Label: PlayingCello\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "True Label: PlayingSitar\n",
            "Predicted Label: PlayingSitar\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "True Label: BandMarching\n",
            "Predicted Label: BandMarching\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: Bowling\n",
            "Predicted Label: Bowling\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: BlowDryHair\n",
            "Predicted Label: BlowDryHair\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: PlayingSitar\n",
            "Predicted Label: PlayingSitar\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "True Label: RockClimbingIndoor\n",
            "Predicted Label: RockClimbingIndoor\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: HammerThrow\n",
            "Predicted Label: HammerThrow\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: ThrowDiscus\n",
            "Predicted Label: ThrowDiscus\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: BoxingPunchingBag\n",
            "Predicted Label: BoxingPunchingBag\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: HammerThrow\n",
            "Predicted Label: HammerThrow\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "True Label: Swing\n",
            "Predicted Label: Swing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: WritingOnBoard\n",
            "Predicted Label: WritingOnBoard\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: WritingOnBoard\n",
            "Predicted Label: WritingOnBoard\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "True Label: BlowingCandles\n",
            "Predicted Label: BlowingCandles\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: BaseballPitch\n",
            "Predicted Label: BaseballPitch\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: BenchPress\n",
            "Predicted Label: BenchPress\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: HammerThrow\n",
            "Predicted Label: HammerThrow\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: PoleVault\n",
            "Predicted Label: PoleVault\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "True Label: BreastStroke\n",
            "Predicted Label: BreastStroke\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "True Label: BaseballPitch\n",
            "Predicted Label: BaseballPitch\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: PlayingDaf\n",
            "Predicted Label: PlayingDaf\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: HorseRiding\n",
            "Predicted Label: HorseRiding\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "True Label: TaiChi\n",
            "Predicted Label: TaiChi\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "True Label: PlayingViolin\n",
            "Predicted Label: PlayingViolin\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: HeadMassage\n",
            "Predicted Label: HeadMassage\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: HulaHoop\n",
            "Predicted Label: HulaHoop\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: SkyDiving\n",
            "Predicted Label: SkyDiving\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: Mixing\n",
            "Predicted Label: Mixing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: BasketballDunk\n",
            "Predicted Label: BasketballDunk\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: CliffDiving\n",
            "Predicted Label: CliffDiving\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "True Label: BabyCrawling\n",
            "Predicted Label: BabyCrawling\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: HeadMassage\n",
            "Predicted Label: HeadMassage\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: HighJump\n",
            "Predicted Label: HighJump\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: SkyDiving\n",
            "Predicted Label: SkyDiving\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "True Label: Archery\n",
            "Predicted Label: Archery\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "True Label: BaseballPitch\n",
            "Predicted Label: BaseballPitch\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: Basketball\n",
            "Predicted Label: Basketball\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "True Label: PlayingFlute\n",
            "Predicted Label: PlayingFlute\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "True Label: Swing\n",
            "Predicted Label: Swing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: SoccerJuggling\n",
            "Predicted Label: SoccerJuggling\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "True Label: Biking\n",
            "Predicted Label: Biking\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: BandMarching\n",
            "Predicted Label: BandMarching\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: CricketShot\n",
            "Predicted Label: CricketShot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: YoYo\n",
            "Predicted Label: YoYo\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: Knitting\n",
            "Predicted Label: Knitting\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: Skijet\n",
            "Predicted Label: Skijet\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "True Label: PlayingGuitar\n",
            "Predicted Label: PlayingGuitar\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: Punch\n",
            "Predicted Label: Punch\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: BabyCrawling\n",
            "Predicted Label: BabyCrawling\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "True Label: BlowDryHair\n",
            "Predicted Label: BlowDryHair\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "True Label: HandstandWalking\n",
            "Predicted Label: Mixing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: ApplyEyeMakeup\n",
            "Predicted Label: ApplyEyeMakeup\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "True Label: BodyWeightSquats\n",
            "Predicted Label: BodyWeightSquats\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: Billiards\n",
            "Predicted Label: Billiards\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "True Label: SumoWrestling\n",
            "Predicted Label: SumoWrestling\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: CliffDiving\n",
            "Predicted Label: CliffDiving\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: VolleyballSpiking\n",
            "Predicted Label: VolleyballSpiking\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: JugglingBalls\n",
            "Predicted Label: JugglingBalls\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: CricketBowling\n",
            "Predicted Label: CricketBowling\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "True Label: PlayingTabla\n",
            "Predicted Label: PlayingTabla\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "True Label: TennisSwing\n",
            "Predicted Label: TennisSwing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: PlayingTabla\n",
            "Predicted Label: PlayingTabla\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "True Label: BenchPress\n",
            "Predicted Label: BenchPress\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
            "True Label: JavelinThrow\n",
            "Predicted Label: JavelinThrow\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "True Label: HandstandPushups\n",
            "Predicted Label: HandstandPushups\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "True Label: BasketballDunk\n",
            "Predicted Label: BasketballDunk\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "True Label: CleanAndJerk\n",
            "Predicted Label: CleanAndJerk\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "True Label: BlowingCandles\n",
            "Predicted Label: BlowingCandles\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "True Label: SumoWrestling\n",
            "Predicted Label: SumoWrestling\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "True Label: RockClimbingIndoor\n",
            "Predicted Label: RockClimbingIndoor\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "True Label: StillRings\n",
            "Predicted Label: StillRings\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "True Label: BenchPress\n",
            "Predicted Label: BenchPress\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
            "True Label: Fencing\n",
            "Predicted Label: Fencing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "True Label: LongJump\n",
            "Predicted Label: BalanceBeam\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "True Label: CricketShot\n",
            "Predicted Label: CricketShot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "True Label: Drumming\n",
            "Predicted Label: Drumming\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
            "True Label: MoppingFloor\n",
            "Predicted Label: MoppingFloor\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "True Label: PizzaTossing\n",
            "Predicted Label: PizzaTossing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
            "True Label: JumpingJack\n",
            "Predicted Label: JumpingJack\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "True Label: HeadMassage\n",
            "Predicted Label: HeadMassage\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "True Label: Rowing\n",
            "Predicted Label: Rowing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: SoccerJuggling\n",
            "Predicted Label: SoccerJuggling\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: Rafting\n",
            "Predicted Label: Rafting\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "True Label: GolfSwing\n",
            "Predicted Label: GolfSwing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "True Label: SoccerJuggling\n",
            "Predicted Label: SoccerJuggling\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "True Label: SoccerJuggling\n",
            "Predicted Label: SoccerJuggling\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: MoppingFloor\n",
            "Predicted Label: MoppingFloor\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "True Label: Biking\n",
            "Predicted Label: Biking\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "True Label: HeadMassage\n",
            "Predicted Label: HeadMassage\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: FrisbeeCatch\n",
            "Predicted Label: FrisbeeCatch\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "True Label: Archery\n",
            "Predicted Label: Archery\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: PlayingPiano\n",
            "Predicted Label: PlayingPiano\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "True Label: JavelinThrow\n",
            "Predicted Label: JavelinThrow\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "True Label: CricketBowling\n",
            "Predicted Label: Skiing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = correct_predictions / total_predictions #Calculate Accuracy For 100 Samples In Test Data\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtFsCcKuCCpu",
        "outputId": "f3a22623-e9ec-44f5-a930-ccad706e3a8a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.00%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}